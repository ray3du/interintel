# Managing Notifications for a Data Streaming Service
Push notifications are a great way of engaging users with timely and relevant information. Handling propotionally large push notifications comes with its own challenges. To make sure the notification system works efficiently I try to develop an API that is as simple as possible.
The notification system will have three primary components:
			
1.	**Notification Server**
2.	**Device ID Store**
3.	**Notification Worker**

### 1. Device ID store
This save the user id of the current logged in user. The user id is removed when the user logout.
The device store facilitates in the process of deciding which devices while get a notification.
###  2. Notification Server
The primary objective of this service will be to expose an API endpoint to send notifications and push as a job on the job queue. This can be a simple HTTP server that accepts the user ID and notification information in the request body e.g
```json
POST http://example.com/notification
user_id: <user_id>
{
	"title": "Test",
	"message": "Test push notification",
	"data": {}
}
```
The server will also fetch all of the users device ids from the  **Device ID  Store** and schedules a job for each of the users device.
#### Task Management and Priotization
To ensure I efficiently manage and priotize the jobs I utilize Celery, Redis, and Flower so that critical tasks are processed promptly.
Priotization of the tasks involves identifying the high-priority tasks are executed immediately while still being able to process low-priority tasks efficiently.
To handle priotization I will leverage Celery's priotization feature. I will assign different priorities to the tasks, with higher values indication lower priority tasks as shown below:
```python
from celery import shared_task

@shared_task(priority=1)
def high_priority_task():
	pass

@shared_task(priority=3)
def medium_priority_task():
	pass

@shared_task(priority=5)
def low_priority_task():
	pass
```
#### Job Management
There will be separate queues for different priorities to handle tasks efficiently. The primary objective of this service is to enable allocation of dedicated works to high priority tasks to ensure prompt execution: The Celery configuration will be updated as illustrated below:
```python
CELERY_TASK_QUEUES = {
'high_priority': {
	'exchange': 'high_priority',
	'exchange_type': 'direct',
	'binding_key': 'high_priority'
	},
'medium_priority': {
	'exchange': 'medium_priority',
	'exchange_type': 'direct',
	'binding_key': 'medium_priority'
	},
'low_priority': {
	'exchange': 'low_priority',
	'exchange_type': 'direct',
	'binding_key': 'low_priority'
	}
}
```

The next step is to update the tasks to their corresponding queus.

```python
from celery import shared_task

@shared_task(priority=0, queue='high_priority')
def  high_priority_task():
	pass

@shared_task(priority=5, queue='medium_priority')
def  medium_priority_task():
	pass

@shared_task(priority=10, queue='low_priority')
def  low_priority_task():
	pass
```
### 3. Notification Worker
The purpose of this service will be to consume messages from the job queus and send it to the respective notification providers.


